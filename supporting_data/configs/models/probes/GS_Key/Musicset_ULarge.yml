MLP:
  activation: relu
  dropout: 0.9
  l2_regularization: 0.0001
  layer_widths:
  - 512
  loss:
    ScoochCategoricalCrossentropy:
      axis: -1
      from_logits: true
      label_smoothing: 0
      name: categorical_crossentropy
      reduction: auto
  metrics:
  - ScoochCategoricalAccuracy: null
  optimizer:
    ScoochAdam:
      amsgrad: false
      beta_1: 0.9
      beta_2: 0.999
      epsilon: 1.0e-07
      learning_rate: 0.001
      name: Adam
      schedule:
        WarmupSchedule:
          cold_learning_rate: 0
          initial_step: 0
          schedule:
            ScoochCosineDecay:
              alpha: 0
              decay_steps: 9000
              initial_learning_rate: 0.0001
              name: null
          warm_learning_rate: 0.0001
          warmup_steps: 1000



