MLP:
  activation: relu
  input_dropout: null
  l2_regularization: 0
  layer_dropouts: null
  layer_widths: []
  loss:
    ScoochCategoricalCrossentropy:
      axis: -1
      from_logits: true
      label_smoothing: 0
      name: categorical_crossentropy
      reduction: auto
  metrics:
  - ScoochAUC:
      curve: PR
      from_logits: true
      multi_label: true
      num_labels: null
  optimizer:
    ScoochAdam:
      amsgrad: false
      beta_1: 0.9
      beta_2: 0.999
      epsilon: 1.0e-07
      learning_rate: 0.001
      name: Adam
      schedule:
        WarmupSchedule:
          cold_learning_rate: 0
          initial_step: 0
          schedule:
            ScoochCosineDecay:
              alpha: 0
              decay_steps: 395000
              initial_learning_rate: 0.0001
              name: null
          warm_learning_rate: 0.0001
          warmup_steps: 5000
  output_dropout: null



